Hadoop权威指南 PDF下载 怀特 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#730237085
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#730237085
<p>书名:Hadoop权威指南</p><p>作者:怀特</p><p>页数:679</p><p>定价:¥99.0</p><p>出版社:清华大学出版社</p><p>出版日期:2015-01-01</p><p>ISBN:9787302370857</p><p><h2>相关资料</h2></p>[<p></p>, <p>
	　　在这本《hadoop权威指南(第3版)》即将出版之际，我十分高兴地再次向广大读者推荐这本书。<br/>
　　一本书的价值最重要的是取决于它的用途。今天，开源的hadoop已经成为研究大数据十分重要的平台，在我国已经形成一个庞大的hadoop用户社群，他们对学习、掌握和提高hadoop提出了很高的需求，《hadoop权威指南(第3版)》恰好满足这样的需要，其用途和价值不言而喻。这一点也可以从下面的事实中得到佐证：从2011年年底出版至今，本书的第2版已经实现了12次印刷，拥有近3.5万名读者并连续两年位列专业图书畅销榜榜首。<br/>
　　一本书的价值还来自于它的内容。原著是用英文写作的，它的内容组织得当，思路清晰，紧密结合实际。但是要把它翻译成中文介绍给中国的读者，并非易事。它不单单要求译者能够熟练地掌握英文，还要求他们对书中的技术性内容有深入、准确的了解和掌握。从这两点来审视，本书的译者团队完全足以胜任。作为大学老师，他们不仅在大数据领域从事一线教学和科研，同时还负责指导研究生从事数据库方面的研究。从 2006 年开始，他们就在计算机集群上部署了hadoop并成功完成了很多项研究。在这几年的工作过程中，他们对hadoop及其应用开发有着深入的理解和认识，这是本书翻译质量有保证的重要前提。<br/>
　　经过再一次升级、修订和更新，值此《hadoop权威指南(第3版)》出版之际，我衷心地希望这本书继续为广大读者带来更高的学习价值，更友好的阅读体验。<br/>
　　周立柱@清华园<br/>
　　2014年秋
</p>, <p align="left">
<br/>
</p>]<p><h2>本书特色</h2></p>[<p>

	　　准备好释放数据的强大潜能了吗？借助于这本《hadoop权威指南》，你将学习如何使用apache hadoop构建和维护稳定性高、伸缩性强的分布式系统。本书是为程序员写的，可帮助他们分析任何大小的数据集。本书同时也是为管理员写的，帮助他们了解如何设置和运行hadoop集群。
　　本书通过丰富的案例学习来解释hadoop的幕后机理，阐述了hadoop如何解决现实生活中的具体问题。第3版覆盖hadoop的*新动态，包括新增的mapreduce api，以及mapreduce 2及其灵活性更强的执行模型（yarn）。
	
		
	


	

                                        </p>]<p><h2>内容简介</h2></p>[<p>
	　　新版新特色，内容更权威，更适合收藏和找hadoop之父签名儿！


	　　2014年12月13日中国大数据大会，http://bdtc2014.hadooper.cn/ 


	　　欢迎光临新云南皇冠假日酒店，与hadoop之父doug cutting不见不散！ 


	
</p>]<p><h2>作者简介</h2></p>[<p>说明: E:2011图书Hadoop权威指南（第2版）Hadoop权威指南第2版infoTom.jpgTom White
　　数学王子&amp;Hadoop专家。身为Apache Hadoop提交者八年之久，Apache软件基金会成员之一。全球知名云计算公司Cloudera的软件工程师。Tom拥有英国剑桥大学数学学士学位和利兹大学科学哲学硕士学位。
　　【推荐序作者介绍】
　　Doug Cutting
　　三大有全球影响力的开源项目之父，Apache软件基金会董事会成员，早年毕业于斯坦福大学。他打造的三大开源项目对企业市场具有重大而深远的影响，其中最著名的当属云计算和大数据领域的明星——Hadoop。

	
</p>]<p><h2>目录</h2></p>
    第1章 初识hadoop 1.1 数据！数据！ 1.2 数据的存储与分析 1.3 相较于其他系统的优势 1.3.1 关系型数据库管理系统 1.3.2 网格计算 1.3.3 志愿计算 1.4 hadoop发展简史 1.5 apache hadoop和hadoop生态系统 1.6 hadoop的发行版本 1.6.1 本书包含的内容 1.6.2 兼容性 第2章 关于mapreduce 2.1 气象数据集 2.2 使用unix工具来分析数据 2.3 使用hadoop来分析数据 2.3.1 map和reduce 2.3.2 java mapreduce 2.4 横向扩展 2.4.1 数据流 2.4.2 combiner函数 2.4.3 运行分布式的mapreduce作业 2.5 hadoop streaming 2.5.1 ruby版本 2.5.2 python版本 2.6 hadoop pipes 第3章 hadoop分布式文件系统 3.1 hdfs的设计 3.2 hdfs的概念 3.2.1 数据块 3.2.2 namenode和datanode 3.2.3 联邦hdfs 3.2.4 hdfs的高可用性 3.3 命令行接口 3.4 hadoop文件系统 3.5 java接口 3.5.1 从hadoop url读取数据 3.5.2 通过filesystem api读取数据 3.5.3 写入数据 3.5.4 目录 3.5.5 查询文件系统 3.5.6 删除数据 3.6 数据流 3.6.1 剖析文件读取 3.6.2 剖析文件写入 3.6.3 一致模型 3.7 通过flume和sqoop导入数据 3.8 通过distcp并行复制 3.9 hadoop存档 3.9.1 使用hadoop存档工具 3.9.2 不足 第4章 hadoop的i／o操作 4.1 数据完整性 4.1.1 hdfs的数据完整性 4.1.2 localfilesystem 4.1.3 checksumfilesystem 4.2 压缩 4.2.1 codec 4.2.2 压缩和输入分片 4.2.3 在mapreduce中使用压缩 4.3 序列化 4.3.1 writable接口 4.3.2 writable类 4.3.3 实现定制的writable集合 4.3 序列化框架 4.4 avro 4.4.1 avro数据类型和模式 4.4.2 内存中的序列化和反序列化 4.4.3 avro数据文件 4.4.4 互操作性 4.4.5 模式的解析 4.4.6 排列顺序 4.4.7 关于avro mapreduce 4.4.8 使用avro mapreduce进行排序 4.4.9 其他语言的avro mapreduce 4.5 基于文件的数据结构 4.5.1 关于sequencefile 4.5.2 关于mapfile 第5章 mapreduce应用开发 5.1 用于配置的api 5.1.1 资源合并 5.1.2 可变的扩展 5.2 配置开发环境 5.2.1 管理配置 5.2.2 辅助类genericoptionsparser，tool和toolrunner 5.3 用mrunit来写单元测试 5.3.1 关于mapper 5.3.2 关于reducer 5.4 本地运行测试数据 5.4.1 在本地作业运行器上运行作业 5.4.2 测试驱动程序 5.5 在集群上运行 5.5.1 打包作业 5.5.2 启动作业 5.5.3 mapreduce的web界面 5.5.4 获取结果 5.5.5 作业调试 5.5.6 hadoop日志 5.5.7 远程调试 5.6 作业调优 5.7 mapreduce的工作流 5.7.1 将问题分解成mapreduce作业 5.7.2 关于jobcontrol 5.7.3 关于apache oozie 第6章 mapreduce的工作机制 6.1 剖析mapreduce作业运行机制 6.1.1 经典的mapreduce （mapreduce 1） 6.1.2 yarn （mapreduce 2） 6.2 失败 6.2.1 经典mapreduce中的失败 6.2.2 yarn中的失败 6.3 作业的调度 6.3.1 公平调度器 6.3.2 容量调度器 6.4 shuffle和排序 6.4.1 map端 6.4.2 reduce端 6.4.3 配置调优 6.5 任务的执行 6.5.1 任务执行环境 6.5.2 推测执行 6.5.3 关于outputcommitters 6.5.4 任务jvm重用 6.5.5 跳过坏记录 第7章 mapreduce的类型与格式 7.1 mapreduce的类型 7.1.1 默认的mapreduce作业 7.1.2 默认的streaming作业 7.2 输入格式 7.2.1 输入分片与记录 7.2.2 文本输入 7.2.3 二进制输入 7.2.4 多个输入 7.2.5 数据库输入（和输出） 7.3 输出格式 7.3.1 文本输出 7.3.2 二进制输出 7.3.3 多个输出 7.3.4 延迟输出 7.3.5 数据库输出 第8章 mapreduce的特性 8.1 计数器 8.1.1 内置计数器 8.1.2 用户定义的java计数器 8.1.3 用户定义的streaming计数器 8.2 排序 8.2.1 准备 8.2.2 部分排序 8.2.3 全排序 8.2.4 辅助排序 8.3 连接 8.3.1 map端连接 8.3.2 reduce端连接 8.4 边数据分布 8.4.1 利用jobconf来配置作业 8.4.2 分布式缓存 8.5 mapreduce库类 第9章 构建hadoop集群 9.1 集群规范 9.2 集群的构建和安装 9.2.1 安装java 9.2.2 创建hadoop用户 9.2.3 安装hadoop 9.2.4 测试安装 9.3 ssh配置 9.4 hadoop配置 9.4.1 配置管理 9.4.2 环境设置 9.4.3 hadoop守护进程的关键属性 9.4.4 hadoop守护进程的地址和端口 9.4.5 hadoop的其他属性 9.4.6 创建用户帐号 9.5 yarn配置 9.5.1 yarn守护进程的重要属性 9.5.2 yarn守护进程的地址和端口 9.6 安全性 9.6.1 kerberos和hadoop 9.6.2 委托令牌 9.6.3 其他安全性改进 9.7 利用基准评测程序测试hadoop集群 9.7.1 hadoop基准评测程序 9.7.2 用户作业 9.8 云端的hadoop 第10章 管理hadoop 10.1 hdfs 10.1.1 永久性数据结构 10.1.2 安全模式 10.1.3 日志审计 10.1.4 工具 10.2 监控 10.2.1 日志 10.2.2 度量 10.2.3 java管理扩展（jmx） 10.3 维护 10.3.1 日常管理过程 10.3.2 委任和解除节点 10.3.3 升级 第11章 关于pig 11.1 安装与运行pig 11.1.1 执行类型 11.1.2 运行pig程序 11.1.3 grunt 11.1.4 pig latin编辑器 11.2 示例 11.3 与数据库进行比较 11.4 pig latin 11.4.1 结构 11.4.2 语句 11.4.3 表达式 11.4.4 类型 11.4.5 模式 11.4.6 函数 11.4.7 宏 11.5 用户自定义函数 11.5.1 过滤udf 11.5.2 计算udf 11.5.3 加载udf 11.6 数据处理操作 11.6.1 数据的加载和存储 11.6.2 数据的过滤 11.6.3 数据的分组与连接 11.6.4 数据的排序 11.6.5 数据的组合和切分 11.7 pig实战 11.7.1 并行处理 11.7.2 参数代换 第12章 关于hive 12.1 安装hive 12.2 示例 12.3 运行hive 12.3.1 配置hive 12.3.2 hive服务 12.3.3 metastore 12.4 hive与传统数据库相比 12.4.1 读时模式vs.写时模式 12.4.2 更新、事务和索引 12.5 hiveql 12.5.1 数据类型 12.5.2 操作与函数 12.6 表 12.6.1 托管表和外部表 12.6.2 分区和桶 12.6.3 存储格式 12.6.4 导入数据 12.6.5 表的修改 12.6.6 表的丢弃 12.7 查询数据 12.7.1 排序和聚集 12.7.2 mapreduce脚本 12.7.3 连接 12.7.4 子查询 12.7.5 视图 12.8 用户定义函数 12.8.1 写udf 12.8.2 写udaf 第13章 关于hbase 13.1 hbase基础 13.2 概念 13.3.1 数据模型的“旋风之旅” 13.3.2 实现 13.3 安装 13.4 客户端 13.4.1 java 13.4.2 avro、rest和thrift 13.5 示例 13.5.1 模式 13.5.2 加载数据 13.5.3 web查询 13.6 hbase和rdbms的比较 13.6.1 成功的服务 13.6.2 hbase 13.6.3 实例：hbase在streamy.com的使用 13.7 praxis 13.7.1 版本 13.7.2 hdfs 13.7.3 用户界面 13.7.4 度量 13.7.5 模式的设计 13.7.6 计数器 13.7.7 批量加载 第14章 关于zookeeper 14.1 安装和运行zookeeper 14.2 示例 14.2.1 zookeeper中的组成员关系 14.2.2 创建组 14.2.3 加入组 14.2.4 列出组成员 14.2.5 删除组 14.3 zookeeper服务 14.3.1 数据模型 14.3.2 操作 14.3.3 实现 14.3.4 一致性 14.3.5 会话 14.3.6 状态 14.4 使用zookeeper来构建应用 14.4.1 配置服务 14.4.2 可复原的zookeeper应用 14.4.3 锁服务 14.4.4 更多分布式数据结构和协议 14.5 生产环境中的zookeeper 14.5.1 可恢复性和性能 14.5.2 配置 第15章 关于sqoop 15.1 获取sqoop 15.2 sqoop连接器 15.3 一个导入的例子 15.4 生成代码 15.5 深入了解数据库导入 15.5.1 导入控制 15.5.2 导入和一致性 15.5.3 直接模式导入 15.6 使用导入的数据 15.7 导入大对象 15.8 执行导出 15.9 深入了解导出功能 15.9.1 导出与事务 15.9.2 导出和sequencefile 第16章 实例学习 16.1 hadoop 在last.fm的应用 16.1.1 last.fm：社会音乐史上的革命 16.1.2 hadoop在last.fm中的应用 16.1.3 用hadoop制作图表 16.1.4 track statistics程序 16.1.5 总结 16.2 hadoop和hive在facebook的应用 16.2.1 hadoop在facebook的使用 16.2.2 虚构的使用样例 16.2.3 hive 16.2.4 存在的问题与未来工作计划 16.3 nutch搜索引擎 16.3.1 背景介绍 16.3.2 数据结构 16.3.3 nutch系统利用hadoop进行数据处理的精选实例 16.3.4 总结 16.4 rackspace的日志处理 16.4.1 要求／问题 16.4.2 简史 16.4.3 选择hadoop 16.4.4 收集和存储 16.4.5 对日志的mapreduce处理 16.5 关于cascading 16.5.1 字段、元组和管道 16.5.2 操作 16.5.3 tap、scheme和flow 16.5.4 cascading实战 16.5.5 灵活性 16.5.6 hadoop和cascading在sharethis的应用 16.5.7 总结 16.6 apache hadoop上万亿数量级排序 16.7 用pig和wukong探索10亿数量级边的网络图 16.7.1 社区判断 16.7.2 每个人都在和我说话：twitter回复关系图 16.7.3 对称链接 16.7.4 社区提取 附录a 安装apache hadoop 附录b 关于cdh 附录c 准备ncdc气象数据 
