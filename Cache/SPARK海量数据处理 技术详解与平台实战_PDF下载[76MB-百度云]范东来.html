SPARK海量数据处理:技术详解与平台实战 PDF下载 范东来 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711550700
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711550700
<p>书名:SPARK海量数据处理:技术详解与平台实战</p><p>作者:范东来</p><p>页数:388</p><p>定价:¥99.0</p><p>出版社:人民邮电出版社</p><p>出版日期:2019-12-01</p><p>ISBN:9787115507006</p><p><h2>本书特色</h2></p>[<p>
本书基于Spark发行版2.4.4写作而成，包含大量的实例与一个完整项目，层次分明，循序渐进。全书分为3部分，涵盖了技术理论与实战，读者可以从实战中巩固学习到的知识。*部分主要围绕BDAS（伯克利数据分析栈），不仅介绍了如何开发Spark应用的基础内容，还介绍了Structured Streaming、Spark机器学习、Spark图挖掘、Spark深度学习等高级主题，此外还介绍了Alluxio系统。第二部分实现了一个企业背景调查系统，比较新颖的是，该系统借鉴了数据湖与Lambda架构的思想，涵盖了批处理、流处理应用开发，并加入了一些开源组件来满足需求，既是对本书*部分很好的巩固，又完整呈现了一个实时大数据应用的开发过程。第三部分是对全书的总结和展望。 本书适合准备学习Spark的开发人员和数据分析师，以及准备将Spark应用到实际项目中的开发人员和管理人员阅读，也适合计算机相关专业的高年级本科生和研究生学习和参考，对于具有一定的Spark使用经验并想进一步提升的数据科学从业者也是很好的参考资料。
                                        </p>]<p><h2>内容简介</h2></p>[<p>本书基于Spark发行版2.4.4写作而成，包含大量的实例与一个完整项目，层次分明，循序渐进。全书分为3部分，涵盖了技术理论与实战，读者可以从实战中巩固学习到的知识。部分主要围绕BDAS（伯克利数据分析栈），不仅介绍了如何开发Spark应用的基础内容，还介绍了Structured Streaming、Spark机器学习、Spark图挖掘、Spark深度学习等不错主题，此外还介绍了Alluxio系统。第二部分实现了一个企业背景调查系统，比较新颖的是，该系统借鉴了数据湖与Lambda架构的思想，涵盖了批处理、流处理应用开发，并加入了一些开源组件来满足需求，既是对本书部分很好的巩固，又完整呈现了一个实时大数据应用的开发过程。第三部分是对全书的总结和展望。
本书适合准备学习Spark的开发人员和数据分析师，以及准备将Spark应用到实际项目中的开发人员和管理人员阅读，也适合计算机相关专业的高年级本科生和研究生学习和参考，对于具有一定的Spark使用经验并想进一步提升的数据科学从业者也是很好的参考资料。</p>]<p><h2>作者简介</h2></p>[<p>范东来，北京航空航天大学硕士，泛山科技联合创始人，Spark Contributor、SupersetContributor，架构师，技术图书作者和译者，著有《Hadoop海量数据处理》，译有《解读NoSQL》《NoSQL权威指南》《神经网络算法和实现》《Hadoop深度学习》《精通数据科学算法》等，另译有畅销小说《巧克力时代：因为这是我的血脉》。</p>]<p><h2>目录</h2></p>
    第 一部分 基础篇第 1章 序篇 21.1 Spark与BDAS 31.2 Databricks 41.3 如何通过GitHub向Spark贡献代码 51.4 如何选择Spark编程语言 81.5 函数式编程思想 91.6 小结 12第 2章 Spark编程 132.1 Spark架构 132.2 Spark 2.x与Spark 3.x 152.2.1 Tungsten项目 162.2.2 统一Dataset和DataFrame 接口 202.2.3 新一代流处理技术：Structured Streaming与持续型应用 212.2.4 Hydrogen项目和Spark 3.x 222.3 部署Spark 262.3.1 Spark on YARN 272.3.2 Spark on Mesos 282.3.3 Spark Standalone 292.3.4 Spark on Kubernetes 302.3.5 安装Spark 312.3.6 提交作业 312.3.7 Spark Shell 332.3.8 初始化SparkSession 342.4 RDD与算子 342.4.1 RDD 342.4.2 创建RDD 362.4.3 转换算子 382.4.4 行动算子 432.4.5 RDD血统与Spark容错 452.5 Spark Shuffle 472.5.1 Hash Shuffle 472.5.2 Sort-based Shuffle 492.6 共享变量 502.6.1 广播变量 502.6.2 累加器 532.7 Spark的多语言支持 552.7.1 PySpark 552.7.2 SparkR 562.8 Spark性能调优 562.8.1 硬件配置与资源管理平台 572.8.2 参数调优与应用调优 572.9 使用Jupyter Notebook基于Spark探索数据：蒙特卡罗方法预测股票价格 642.9.1 Jupyter Notebook 642.9.2 用蒙特卡罗方法预测股票价格 672.10 小结 70第3章 Spark统一编程接口：DataFrame、Dataset和Spark SQL 713.1 Catalyst优化器 723.1.1 SQL抽象语法树 723.1.2 从ULEP到RLEP的过程 733.1.3 调优RLEP 733.1.4 全阶段代码生成 743.2 DataFrame API 753.2.1 创建DataFrame 753.2.2 查询 773.2.3 窗口函数 803.2.4 用户自定义函数 833.2.5 写入 853.3 Dataset API 863.3.1 RDD、DataFrame和Dataset 873.3.2 安全类型的UDAF 883.4 Spark SQL 893.4.1 创建临时视图 903.4.2 使用Hive元数据 903.4.3 查询语句 913.4.4 函数 943.4.5 用户自定义函数 973.5 Google Dremel与列式存储 973.5.1 Apache Parquet 993.5.2 Apache ORC 1003.5.3 Apache CarbonData 1003.5.4 对比测试 1013.6 使用Spark SQL进行数据探索 1023.7 小结 107第4章 Spark流处理：Spark Streaming与Structured Streaming 1084.1 一个Spark Streaming流处理的例子 1094.2 消息送达保证 1104.3 Google MillWheel系统和Google Dataflow模型 1144.3.1 Google MillWheel设计思想 1144.3.2 Google MillWheel如何实现“恰好一次”消息送达语义 1144.3.3 Google MillWheel对乱序数据与晚到数据的处理 1154.3.4 Google Dataflow：流处理和批处理的统一与取舍 1174.4 Spark Streaming 1224.4.1 关键抽象与架构 1234.4.2 无状态的转换算子 1254.4.3 有状态的转换算子 1294.4.4 输入与输出 1344.4.5 Spark Streaming与Spark SQL 1384.4.6 容错与结果正确性 1394.4.7 性能调优 1414.5 Structured Streaming 1444.5.1 关键抽象与架构 1444.5.2 操作 1474.5.3 输入和输出 1544.5.4 股票交易价格实时分析 1574.6 流处理技术对比 1624.7 小结 163第5章 Spark图计算：GraphX 1645.1 图模式 1645.1.1 图结构 1645.1.2 图存储 1655.1.3 图数据库 1685.1.4 图挖掘技术 1695.1.5 属性图与RDF 1705.2 生成图 1715.2.1 从已有数据中生成 1725.2.2 通过GraphGenerators生成 1745.3 图算子 1755.3.1 属性算子 1755.3.2 结构算子 1755.3.3 连接算子 1755.3.4 aggregateMessages 1765.4 Pregel API 1775.4.1 图分区 1775.4.2 像顶点一样思考 1805.4.3 用户自定义函数 1825.4.4 PageRank的GraphX实现 1835.4.5 标签传播算法 1865.5 SQL on Graph 1875.5.1 生成图 1885.5.2 SQL查询 1895.5.3 模式发现 1905.5.4 一些GraphX已经有的算法 1915.5.5 一些GraphX没有的算法 1915.5.6 AggregateMessages 1925.6 n度邻居顶点算法 1935.7 小结 196第6章 Spark机器学习：MLlib 1976.1 机器学习 1976.1.1 典型的机器学习工作流 1986.1.2 机器学习任务的学习类型 1996.2 Spark MLlib与Spark ML 2016.3 数据预处理 2056.3.1 数据标准化 2056.3.2 缺失值处理 2076.3.3 特征抽取 2086.3.4 特征选择 2126.4 分类算法应用 2146.4.1 决策树 2146.4.2 随机森林 2176.4.3 人体状态监测器 2186.4.4 集成学习 2236.4.5 梯度提升决策树 2246.5 聚类算法应用 2256.5.1 物以类聚 2256.5.2 k均值聚类算法 2266.5.3 实现 2276.6 推荐系统应用 2306.6.1 基于用户的协同过滤 2316.6.2 基于商品的协同过滤 2336.6.3 两种协同过滤的对比 2356.6.4 基于模型的协同过滤 2366.6.5 Movielens电影推荐系统 2376.7 训练之后 2386.7.1 模型评估 2396.7.2 交叉验证与超参调优 2416.8 流式机器学习 2426.8.1 流回归 2426.8.2 流聚类 2446.8.3 用流处理应用来监控模型 2456.9 小结 249第7章 Spark深度学习：Deeplearning4j 2507.1 常见的深度学习框架 2517.2 Deeplearning4j 2527.3 卷积神经网络 2527.3.1 理解卷积神经网络 2527.3.2 用Deeplearning4j训练卷积神经网络 2547.4 循环神经网络 2577.4.1 理解循环神经网络 2587.4.2 用Deeplearning4j训练循环神经网络 2627.5 自动编码器 2647.5.1 理解自动编码器 2647.5.2 用Deeplearning4j训练自动编码器 2677.6 使用GPU 2697.7 小结 270第8章 分布式存储：Alluxio 2718.1 Alluxio架构 2718.1.1 Alluxio的组成部分 2738.1.2 虚拟的Alluxio 2738.1.3 统一而透明的命名空间 2748.2 快速上手Alluxio 2758.2.1 安装Alluxio 2758.2.2 Alluxio配置 2768.2.3 Alluxio血统机制 2778.3 与上层框架集成 2778.3.1 与Spark集成 2788.3.2 与Presto集成 2798.3.3 与HBase集成 2808.4 与底层存储系统集成 2818.4.1 与Ceph集成 2818.4.2 挂载其他文件系统 2818.5 如何访问Alluxio 2828.6 Alluxio应用案例 2838.6.1 携程网 2838.6.2 滴滴出行 2848.6.3 陌陌 2868.7 小结 288第二部分 应用篇第9章 企业数据湖与Lambda架构 2909.1 数据湖 2909.1.1 数据的湖泊 2909.1.2 数据湖要解决的问题 2919.1.3 数据湖与数据仓库对比 2929.1.4 数据湖如何工作 2939.2 Lambda架构 2939.2.1 批处理层 2949.2.2 服务层 2959.2.3 速度层 2959.2.4 Lambda架构 2969.2.5 Lambda架构的原则 2979.3 基于Lambda架构的数据湖分层设计 2979.3.1 数据获取层 2989.3.2 消息层 2999.3.3 数据摄取层 3009.3.4 数据存储层 3009.3.5 Lambda层 3019.4 Lambda架构的应用 3019.4.1 搜索引擎 3019.4.2 Druid 3029.5 构建Lambda架构的技术 3039.6 小结 304第 10章 大数据企业动态背景调查平台 30510.1 企业背景调查 30510.2 基于大数据的企业动态背景调查 30810.2.1 企业行为信息 30810.2.2 企业关联方分析 31110.3 数据采集与数据字典 31310.4 企业背景调查平台需求 31710.4.1 企业关联图谱展示 31710.4.2 企业风险指标计算 31810.5 企业关联图谱的模式 31810.6 传统数据仓库架构 32010.7 小结 321第 11章 平台设计 32211.1 平台架构 32211.1.1 数据源 32311.1.2 数据管道 32311.1.3 速度层 32511.1.4 批处理层 32511.1.5 服务层 32511.1.6 查询层 32511.1.7 可视化组件 32511.2 物理拓扑 32611.3 服务层图数据库设计 32611.4 项目规划 32711.5 小结 327第 12章 数据管道层 32812.1 安装并配置canal 32812.2 实现Kafka生产者 33012.3 安装并配置Flume 33512.4 小结 336第 13章 速度层 33713.1 速度层输入 33713.1.1 类型1 33813.1.2 类型2 33813.1.3 类型3 33913.1.4 类型4 34013.2 Cypher基础 34113.2.1 写入 34213.2.2 读取 34313.2.3 删除 34413.3 生成Cypher语句 34513.3.1 类型1 34513.3.2 类型2 34613.3.3 类型3 34613.3.4 类型4 34613.3.5 实现 34713.4 整合Structured Streaming 35213.4.1 Neo4jWriter 35313.4.2 启动流 35413.5 小结 355第 14章 批处理层 35614.1 自融风险监测 35614.2 生成主数据集 35714.2.1 全量与增量 35814.2.2 合并 35914.2.3 数据治理 36114.3 用GraphX计算企业自融风险值 36314.4 导入HBase 36414.5 调度中心 36614.5.1 Airflow 36614.5.2 配置 36814.6 小结 370第 15章 服务层与查询层 37115.1 不仅仅是合并 37115.1.1 NetworkX 37215.1.2 计算流程 37215.2 接口开发 37215.3 小结 376第三部分 总结篇第 16章 总结和展望 37816.1 统一的大数据处理接口 37816.1.1 Unified Spark 37816.1.2 Apache Beam 37916.2 Kappa架构 38016.3 大数据处理技术 38216.3.1 Apache Flink 38216.3.2 Apache Apex 38316.3.3 Ray 38416.4 Spark未来发展方向 386
