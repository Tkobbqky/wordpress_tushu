HAWQ数据仓库与数据挖掘实战 PDF下载 王雪迎著 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#730249802
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#730249802
<p>书名:HAWQ数据仓库与数据挖掘实战</p><p>作者:王雪迎 著</p><p>页数:578</p><p>定价:¥98.0</p><p>出版社:清华大学出版社</p><p>出版日期:2018-04-01</p><p>ISBN:9787302498025</p><p><h2>节选</h2></p>[<p>1.4 为什么选择HAWQ 
前面已经介绍了几种常用SQL-on-Hadoop 的实现方式，也了解了HAWQ的功能特性与系 
统架构。那么站在用户的角度，我们为什么要选择HAWQ？近年来我尝试过几种 
SQL-on-Hadoop 产品，从*初的Hive，到Spark SQL，再到Impala，在这些产品上进行了一系 
列ETL、CDC、多维数据仓库、OLAP 实验。从数据库的角度看，这些产品与传统的DBMS 
相比，功能不够完善，性能差距很大，甚至很难找到一个相对完备的Hadoop 数据仓库解决方 
案。这里就以个人的实践体验来简述这些产品的不足以及HAWQ的可行性。 
1.4.1 常用SQL-on-Hadoop产品的不足 
1. Hive 
Hive 是一款老牌的Hadoop 数据仓库产品，能够部署在所有Hadoop 发行版本上。它在 
MapReduce 计算框架上封装一个SQL 语义层，极大简化了MR 程序的开发。直到现在，Hive 
依然以其稳定性赢得了大量用户。 
Hive 的缺点也很明显——速度太慢。随着技术的不断进步，Hive 的执行引擎从MapReduce 
发展出Hive on Spark、Hive on Tez等。特别是运行在Tez 框架上的Hive，其性能有了很大改 
进。即便如此，Hive 的速度还是比较适合后台批处理应用场景，而不适合交互式即时查询和 
联机分析。 
第1章 HAWQ 概述 
2. Spark SQL 
Spark SQL是Hadoop 中另一个著名的SQL 引擎，正如名字所表示的，它以Spark 作为底 
层计算框架，实际上是一个Scala 程序语言的子集。Spark 基本的数据结构是RDD，一个分布 
于集群节点的只读数据集合。传统的MapReduce 框架强制在分布式编程中使用一种特定的线 
性数据流处理方式。MapReduce 程序从磁盘读取输入数据，把数据分解成键/值对，经过混洗、 
排序、归并等数据处理后产生输出，并将*终结果保存在磁盘。Map 阶段和Reduce 阶段的结 
果均要写磁盘，这大大降低了系统性能。也是由于这个原因，MapReduce 大都被用于执行批 
处理任务。 
为了解决MapReduce 的性能问题，Spark使用RDD 共享内存结构。这种内存操作减少了 
磁盘IO，大大提高了计算速度。开发Spark 的初衷是用于机器学习系统的培训算法，而不是 
SQL 查询。Spark 宣称其应用的延迟可以比MapReduce 降低几个数量级，但是在我们的实际 
使用中，20TB 的数据集合上用Spark SQL 查询要10 分钟左右出结果，这个速度纵然是比Hive 
快了4 倍，但显然不能支撑交互查询和OLAP应用。Spark 还有一个问题，即需要占用大量内 
存，当内存不足时，很容易出现OOM错误。 
3. Impala 
Impala 的*大优势在于执行速度。官方宣称大多数情况下它能在几秒或几分钟内返回查 
询结果，而相同的Hive 查询通常需要几十分钟甚至几小时完成，因此Impala 适合对Hadoop 
文件系统上的数据进行分析式查询。Impala 默认使用Parquet 文件格式，这种列式存储方式对 
于典型数据仓库场景下的大查询是较为高效的。 
Impala 的问题主要体现在功能上的欠缺。例如，不支持Date 数据类型，不支持XML 和 
JSON 相关函数，不支持covar_pop、covar_samp、corr、percentile、 percentile_approx、 
histogram_numeric、collect_set 等聚合函数，不支持rollup、cube、grouping set 等操作，不支 
持数据抽样（Sampling），不支持ORC 文件格式，等等。其中，分组聚合、取中位数等是数 
据分析中的常用操作，当前的Impala 存在如此多的局限，使它在可用性上大打折扣，实际使 
用时要格外注意。 
</p>]<p><h2>本书特色</h2></p>[<p>

                                HAWQ安装、连接、对象与资源管理、查询优化、备份恢复、高可用性、运维监控 
ETL处理、自动调度系统、维度表与事实表技术、OLAP与数据的图形化表示 
降维、协同过滤、关联规则、回归、聚类、分类等常见数据挖掘与机器学习方法 
            
                                        </p>]<p><h2>内容简介</h2></p>[<p>Apache HAWQ是一个SQL-on-Hadoop产品，它很好适合用于Hadoop平台上快速构建数据仓库系统。HAWQ具有大规模并行处理、完善的SQL兼容性、支持存储过程和事务、出色的性能表现等特性，还可与开源数据挖掘库MADlib轻松整合，从而使用SQL就能进行数据挖掘与机器学习。《HAWQ数据仓库与数据挖掘实战》内容分技术解析、实战演练与数据挖掘三个部分共27章。技术解析部分说明HAWQ的基础架构与功能特性，包括安装、连接、对象与资源管理、查询优化、备份恢复、高可用性等。实战演练部分用一个完整的示例，说明如何使用HAWQ取代传统数据仓库，包括ETL处理、自动调度系统、维度表与事实表技术、OLAP与数据的图形化表示等。数据挖掘部分用实例说明HAWQ与MADlib整合，实现降维、协同过滤、关联规则、回归、聚类、分类等常见数据挖掘与机器学习方法。《HAWQ数据仓库与数据挖掘实战》适合数据库管理员、大数据技术人员、Hadoop技术人员、数据仓库技术人员，也适合高等院校和培训机构相关专业的师生教学参考。</p>]<p><h2>作者简介</h2></p>[<p>王雪迎 ，王雪迎 ，毕业于中国地质大学计算机专业，高级工程师，从事数据库、数据仓库相关技术工作20年。先后供职于北京现代商业信息技术有限公司、北京在线九州信息技术服务有限公司、华北计算技术研究所、北京优贝在线网络科技有限公司，担任DBA、数据架构师等职位。著有图书《Hadoop数据仓库实践》。</p>]