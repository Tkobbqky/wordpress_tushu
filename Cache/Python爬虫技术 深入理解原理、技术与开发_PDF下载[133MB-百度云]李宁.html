Python爬虫技术:深入理解原理、技术与开发 PDF下载 李宁 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#730253568
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#730253568
<p>书名:Python爬虫技术:深入理解原理、技术与开发</p><p>作者:李宁</p><p>页数:未知</p><p>定价:¥89.0</p><p>出版社:清华大学出版社</p><p>出版日期:2020-01-01</p><p>ISBN:9787302535683</p><p><h2>相关资料</h2></p>[<p>《Python爬虫技术——深入理解原理、技术与开发》一书诠释了Python爬虫的核心开发技术。不管是“菜鸟”，还是“高手”，都可从本书受益。更难能可贵的是，本书提供了大量的实战案例，通过各种爬虫技术抓取的不同种类的信息和实战，读者可以更好地掌握爬虫应用的编写过程。<br/>——金晓颖  触控科技有限公司副总裁<br/>李宁是51CTO学院金牌讲师、51CTO学院专家级博主，在IT技术领域有很深的造诣。他授课风趣幽默，讲解条理清晰、通俗易懂，对如何学习编程技术有独到见解。他在51CTO学院已开设了150多门视频课程，学员达130多万人，视频课程广受好评。一个如此受欢迎的老师，他编写的图书也非常值得阅读。更重要的是，本书配套提供了大量的实战项目、源代码、练习题，能方便读者快速实践，所以强烈推荐此书！<br/>——曹亚莉  51CTO学院教学总监<br/>    看到李宁老师的30多本图书和150多门视频课程，我不禁惊叹于他如此强大的能力、精力和毅力。在51CTO学院，李宁老师的听课人数达到130多万。他编写的图书更是紧跟IT技术发展潮流，这本《Python爬虫技术——深入理解原理、技术与开发》也是顺应时代发展的大作。全书内容涵盖了基础知识、高级编程、理论知识与典型应用，是学习Python编程的优秀教材。<br/>——韩立刚  51CTO学院金牌讲师   <br/>    《Python爬虫技术——深入理解原理、技术与开发》一书体现了李宁老师一贯的个人教学风格。书中知识全面、案例丰富，是Python初学者难得的入门好书！推荐阅读！<br/>——谢星星（网名阿蜜果）  软通动力资深架构师<br/>李宁老师工作勤奋，技术精湛。他录制了大量优秀的IT视频课程，Python视频课程是其中的代表作。Python是目前*受欢迎的编程语言，而Python爬虫是Python应用*火的领域。毫无疑问，《Python爬虫技术——深入理解原理、技术与开发》是一本*的Python爬虫实践指南。<br/>——朱有鹏  朱老师物联网大讲堂创始人<br/>《Python爬虫技术——深入理解原理、技术与开发》是一本经典的Python爬虫高级教程，本书层次鲜明、结构严谨、内容翔实，可以带领读者快速掌握Python爬虫的核心知识，帮助读者编写解决实际问题的代码并开发复杂项目。 <br/>——江清清  嘎嘎软件科技公司总经理
 </p>]<p><h2>本书特色</h2></p>[<p>
本书从实战角度系统讲解 Python爬虫的核心知识点，并通过大量的真实项目让读者熟练掌握 Python爬虫技术。本书用 20多个实战案例，完美演绎了使用各种技术编写 Python爬虫的方式，读者可以任意组合这些技术，完成非常复杂的爬虫应用。 全书共 20章，分为 5篇。第 1篇基础知识（第 1、2章），主要包括 Python运行环境的搭建、 HTTP基础、网页基础（ HTML、CSS、JavaScript等）、爬虫的基本原理、 Session与 Cookie。第 2篇网络库（第 3～ 6章），主要包括网络库 urllib、urllib3、requests和 Twisted的核心使用方法，如发送 HTTP请求、处理超时、设置 HTTP请求头、搭建和使用代理、解析链接、 Robots协议等。第 3篇解析库（第 7～ 10章），主要包括 3个常用解析库（ lxml、Beautiful Soup和 pyquery）的使用方法，同时介绍多种用于分析 HTML代码的技术，如正则表达式、 XPath、CSS选择器、方法选择器等。第 4篇数据存储（第 11、12章），主要包括 Python中数据存储的解决方案，如文件存储和数据库存储，其中数据库存储包括多种数据库，如本地数据库 SQLite、网络数据库 MySQL以及文档数据库 MongoDB。第 5篇爬虫高级应用（第 13～ 20章），主要包括 Python爬虫的一些高级技术，如抓取异步数据、 Selenium、Splash、抓取移动 App数据、 Appium、多线程爬虫、爬虫框架 Scrapy，*后给出一个综合的实战案例，综合了 Python爬虫、数据存储、 PyQt5、多线程、数据可视化、Web等多种技术实现一个可视化爬虫。 本书可以作为广大计算机软件技术开发者、互联网技术研究人员学习“爬虫技术”的参考用书。也可以作为高等院校计算机科学与技术、软件工程、人工智能等专业的教学参考用书。
                                        </p>]<p><h2>内容简介</h2></p>[<p>JetBrains大中华区市场部经理赵磊作序！超过300个实战案例，10万行源代码，22个综合实战项目，海量学习资料，1000套中英文简历模板。全书内容涵盖：<br/>李宁 “私房菜谱”<br/>? Python爬虫基础知识<br/>? Python网络库<br/>? Python解析库<br/>? Python数据存储<br/>? Python异步数据抓取<br/>? Python移动App数据抓取<br/>? Python可见即可爬<br/>? Python Scrapy实战<br/>? Python项目实战<br/>李宁“实战项目”<br/>? 抓取小说目录与正文<br/>? 抓取豆瓣网图书榜单<br/>? 抓取房屋租赁信息<br/>? 抓取豆瓣网音乐排行榜<br/>? 抓取百度网站图片搜索中的图片<br/>? 抓取QQ空间说说<br/>? 可视化爬虫抓取和分析当当网图书评论 </p>]<p><h2>作者简介</h2></p>[<p>李宁   欧瑞科技创始人&amp;CEO，宁哥教育创始人，东北大学计算机专业硕士。曾任国内某大型软件公司项目经理、宁哥教育教学总监、51CTO学院金牌讲师、CSDN特级讲师。从事软件研究和开发超过15年，一直从事Python、人工智能、区块链、JavaScript、Node.js、Java以及跨平台技术的研究和技术指导工作，对国内外相关领域的技术、理论和实践有很深的理解和研究。</p>]<p><h2>目录</h2></p>
    第 1篇基础知识第 1章开发环境配置 ................................. 2 
1.1 安装官方的 Python运行环境 .........................2 
1.2  配置 PATH环境变量.....................................5 
1.3 安装 Anaconda Python开发环境 ...................6 
1.4 安装 PyCharm ...............................................7 
1.5 配置 PyCharm ...............................................8 
1.6  小结 ........................................................... 10
第 2章爬虫基础.......................................11 
2.1 HTTP基础...................................................... 11 
2.1.1  URI和 URL ........................................ 11 
2.1.2  超文本 ................................................ 12 
2.1.3  HTTP与 HTTPS ................................. 12 
2.1.4  HTTP的请求过程 ............................... 15 
2.1.5  请求 .................................................... 17 
2.1.6  响应 .................................................... 20 
2.2 网页基础 ........................................................ 23 
2.2.1  HTML ................................................. 23 
2.2.2  CSS .................................................... 24 
2.2.3  CSS选择器......................................... 25 
2.2.4  JavaScript ........................................... 27 
2.3 爬虫的基本原理 .............................................. 27 
2.3.1  爬虫的分类 ......................................... 27 
2.3.2  爬虫抓取数据的方式和手段 ................. 28 
2.4 Session与 Cookie ........................................... 28 
2.4.1  静态页面和动态页面 ........................... 29 
2.4.2  无状态 HTTP与 Cookie ...................... 30 
2.4.3  利用 Session和 Cookie保持状态 ......... 30 
2.4.4  查看网站的 Cookie .............................. 31 
2.4.5  HTTP状态何时会失效 ........................ 32 
CONTENTS 目 录2.5 实战案例：抓取所有的网络资源 ..................... 33 
2.6 实战案例：抓取博客文章列表 ......................... 37 
2.7 小结 ............................................................... 40
第 2篇网络库第 3章网络库 urllib ................................. 42 
3.1  urllib简介 ...................................................... 42 
3.2  发送请求与获得响应 ....................................... 43 
3.2.1  用 urlopen函数发送 HTTP GET请求 .................................................... 43 3.2.2  用 urlopen函数发送 HTTP POST请求 .................................................... 44 3.2.3  请求超时 ............................................. 45 
3.2.4  设置 HTTP请求头 .............................. 46 
3.2.5  设置中文 HTTP请求头 ....................... 48 
3.2.6  请求基础验证页面 ............................... 50 
3.2.7  搭建代理与使用代理 ........................... 54 
3.2.8  读取和设置 Cookie .............................. 56 
3.3  异常处理 ........................................................ 60 
3.3.1 URLError ............................................60 
3.3.2 HTTPError ..........................................61 
3.4  解析链接 ........................................................ 62 
3.4.1  拆分与合并 URL（urlparse与 urlunparse） ....................... 62 3.4.2  另一种拆分与合并 URL的方式（urlsplit与 urlunsplit） .......................... 63 3.4.3  连接 URL（urljoin） ............................. 65 
3.4.4  URL编码（urlencode）......................... 65 
3.4.5  编码与解码（quote与 unquote）........... 66 
3.4.6  参数转换（parse_qs与 parse_qsl） ........ 66 
3.5  Robots协议 .................................................... 67 
3.5.1 Robots协议简介 ................................. 67 
3.5.2 分析 Robots协议 ................................ 68 
3.6 小结 ............................................................... 69
第 4章网络库 urllib3 ............................... 70 
4.1 urllib3简介 .................................................... 70 
4.2 urllib3模块 .................................................... 70 
4.3 发送 HTTP GET请求 ...................................... 71 
4.4 发送 HTTP POST请求 .................................... 72 
4.5 HTTP请求头 .................................................. 74 
4.6 HTTP响应头 .................................................. 76 
4.7 上传文件 ........................................................ 76 
4.8 超时 ............................................................... 78 
4.9 小结 ............................................................... 79
第 5章网络库 requests ........................... 80 
5.1 基本用法 ........................................................ 80 
5.1.1  requests的 HelloWorld ........................ 81 
5.1.2  GET请求 ............................................ 81 
5.1.3  添加 HTTP请求头 .............................. 82 
5.1.4  抓取二进制数据 .................................. 83 
5.1.5  POST请求 .......................................... 84 
5.1.6  响应数据 ............................................. 85 
5.2 高级用法 ........................................................ 87 
5.2.1  上传文件 ............................................. 88 
5.2.2  处理 Cookie ........................................ 89 
5.2.3  使用同一个会话（Session） .................. 90 
5.2.4  SSL证书验证...................................... 91 
5.2.5  使用代理 ............................................. 94 
5.2.6  超时 .................................................... 95 
5.2.7  身份验证 ............................................. 97 
5.2.8  将请求打包 ......................................... 97 
5.3 小结 ............................................................... 98
第 6章 Twisted网络框架.......................... 99 
6.1 异步编程模型 ................................................. 99 
6.2 Reactor（反应堆）模式 ................................. 101 
6.3 HelloWorld，Twisted框架 ............................ 101 
6.4 用 Twisted实现时间戳客户端........................ 103 
6.5 用 Twisted实现时间戳服务端........................ 104 
6.6 小结 ............................................................. 105
第 3篇解析库第 7章正则表达式 ................................. 108 
7.1 使用正则表达式 ............................................ 108 
7.1.1  使用 match方法匹配字符串 .............. 108 
7.1.2  使用 search方法在一个字符串中查找模式 ........................................... 109 7.1.3  匹配多个字符串 ................................ 110 
7.1.4  匹配任何单个字符 ............................. 111 
7.1.5  使用字符集 ....................................... 112 
7.1.6  重复、可选和特殊字符 ...................... 114 
7.1.7  分组 .................................................. 117 
7.1.8  匹配字符串的起始和结尾以及单词边界 ........................................... 118 7.1.9  使用 findall和 finditer查找每一次出现的位置 ............................. 120 7.1.10 用 sub和 subn搜索与替换............... 121 
7.1.11 使用 split分隔字符串 ...................... 122 
7.2 一些常用的正则表达式 ................................. 123 
7.3 项目实战：抓取小说目录和全文 ................... 124 
7.4 项目实战：抓取猫眼电影 Top100榜单 .......... 128 
7.5 项目实战：抓取糗事百科网的段子 ................ 133 
7.6 小结 ............................................................. 136
第 8章 lxml与 XPath ............................. 137 
8.1 lxml基础...................................................... 137 
8.1.1  安装 lxml .......................................... 137 
8.1.2  操作 XML ......................................... 138 
8.1.3  操作 HTML ....................................... 140 
8.2 XPath ........................................................... 141 
8.2.1  XPath概述 ........................................ 141 
8.2.2  使用 XPath ........................................ 141 
8.2.3  选取所有节点 .................................... 143 
8.2.4  选取子节点 ....................................... 145 
8.2.5  选取父节点 ....................................... 146 
8.2.6  属性匹配与获取 ................................ 146 
8.2.7  多属性匹配 ....................................... 147 
8.2.8  按序选择节点 .................................... 148 
8.2.9  节点轴选择 ....................................... 149 
8.2.10  在 Chrome中自动获得 XPath代码 .... 151 8.2.11  使用 Chrome验证 XPath ................. 153 
8.3 项目实战：抓取豆瓣 Top250图书榜单 .......... 154 
8.4 项目实战：抓取起点中文网的小说信息 ......... 158 
8.5 小结 ............................................................. 161
第 9章 Beautiful Soup库....................... 162 
9.1 Beautiful Soup简介 ...................................... 162 
9.2 Beautiful Soup基础 ...................................... 162 
9.2.1  安装 Beautiful Soup .......................... 163 
9.2.2  选择解析器 ....................................... 164 
9.2.3  编写**个 Beautiful Soup程序 ........ 164 
9.3 节点选择器 ................................................... 165 
9.3.1  选择节点 ........................................... 165 
9.3.2  嵌套选择节点 .................................... 167 
9.3.3  选择子节点 ....................................... 168 
9.3.4  选择父节点 ....................................... 171 
9.3.5  选择兄弟节点 .................................... 172 
9.4 方法选择器 ................................................... 174 
9.4.1  find_all方法 ..................................... 174 
9.4.2  find方法 ........................................... 177 
9.5 CSS选择器 ................................................... 178 
9.5.1  基本用法 ........................................... 179 
9.5.2  嵌套选择节点 .................................... 180 
9.5.3  获取属性值与文本 ............................. 181 
9.5.4  通过浏览器获取 CSS选择器代码....... 182 
9.6 实战案例：抓取租房信息 .............................. 184 
9.7 实战案例：抓取酷狗网络红歌榜 ................... 188 
9.8 小结 ............................................................. 191
第 10章 pyquery库 ............................... 192 
10.1 pyquery简介 ............................................... 192 
10.2 pyquery基础 ............................................... 192 
10.2.1  安装 pyquery ................................... 193 
10.2.2  pyquery的基本用法 ........................ 193 
10.3 CSS选择器 ................................................. 194 
10.4 查找节点..................................................... 196 
10.4.1  查找子节点 ..................................... 196 
10.4.2  查找父节点 ..................................... 197 
10.4.3  查找兄弟节点 .................................. 198 
10.4.4  获取节点信息 .................................. 199 
10.5  修改节点..................................................... 203 
10.5.1  添加和移除节点的样式（addClass和 removeClass）............... 204 10.5.2  修改节点属性和文本内容（attr、removeAttr、text和 html）...... 205 10.5.3  删除节点（remove） ......................... 207 
10.6  伪类选择器 ................................................. 208 
10.7  项目实战：抓取当当图书排行榜.................. 210 
10.8  项目实战：抓取京东商城手机销售排行榜.... 213 10.9  小结............................................................ 219
第 4篇数据存储第 11章文件存储 .................................. 222 
11.1 打开文件 ..................................................... 222 
11.2  操作文件的基本方法 ................................... 224 
11.2.1  读文件和写文件 .............................. 224 
11.2.2  读行和写行 ..................................... 226 
11.3  使用 FileInput对象读取文件 ....................... 227 
11.4  处理 XML格式的数据 ................................. 228 
11.4.1  读取与搜索 XML文件 ..................... 228 
11.4.2  字典转换为 XML字符串 ................. 229 
11.4.3  XML字符串转换为字典 .................. 231 
11.5  处理 JSON格式的数据................................ 232 
11.5.1  JSON字符串与字典互相转换 .......... 233 
11.5.2  将 JSON字符串转换为类实例 .......... 234 
11.5.3  将类实例转换为 JSON字符串 .......... 236 
11.5.4   类实例列表与 JSON字符串互相转换 ................................................ 236 11.6 将 JSON字符串转换为 XML字符串 ............ 237 
11.7  CSV文件存储 ............................................. 238 
11.7.1  写入 CSV文件 ................................ 238 
11.7.2  读取 CSV文件 ................................ 241 
11.8  小结 ............................................................ 241
第 12章数据库存储............................... 242 
12.1  SQLite数据库 ............................................. 242 
12.1.1 管理 SQLite数据库 ......................... 243 
12.1.2 用 Python操作 SQLite数据库 ......... 245 
12.2 MySQL数据库 ........................................... 247 
12.2.1 安装 MySQL ................................... 247 
12.2.2 在 Python中使用 MySQL ................ 250 
12.3 非关系型数据库 .......................................... 253 
12.3.1 NoSQL简介.................................... 253 
12.3.2 MongoDB数据库 ........................... 253 
12.3.3 pymongo模块 ................................. 255 
12.4 项目实战：抓取豆瓣音乐排行榜.................. 256 
12.5 项目实战：抓取豆瓣电影排行榜.................. 260 
12.6 小结............................................................ 264
第 5篇爬虫高级应用第 13章抓取异步数据 ........................... 266 
13.1 异步加载与 AJAX ....................................... 266 
13.2 基本原理..................................................... 267 
13.3 逆向工程..................................................... 270 
13.4 提取结果..................................................... 274 
13.5 项目实战：支持搜索功能的图片爬虫 ........... 274 
13.6 项目实战：抓取京东图书评价 ..................... 279 
13.7 小结............................................................ 284
第 14章可见即可爬：Selenium .............. 285 
14.1 安装 Selenium ............................................. 286 
14.2 安装 WebDriver .......................................... 286 
14.2.1 安装 ChromeDriver.......................... 287 
14.2.2 装 Edge WebDriver .......................... 288 
14.2.3 安装其他浏览器的 WebDriver .......... 289 
14.3 Selenium的基本使用方法 ........................... 289 
14.4 查找节点..................................................... 293 
14.4.1 查找单个节点 .................................. 293 
14.4.2 查找多个节点 .................................. 295 
14.5 节点交互..................................................... 297 
14.6 动作链 ........................................................ 298 
14.7 执行 JavaScript代码 ................................... 301 
14.8 获取节点信息 .............................................. 302 
14.9 管理 Cookies ............................................... 303 
14.10 改变节点的属性值 ..................................... 304 
14.11 项目实战：抓取 QQ空间说说的内容 ......... 306 
14.12 小结 .......................................................... 308
第 15章基于 Splash的爬虫 ................... 309 
15.1 Splash基础 ................................................. 309 
15.1.1 Splash功能简介 .............................. 309 
15.1.2 安装 Docker .................................... 310 
15.1.3 安装 Splash ..................................... 310 
15.2  Splash Lua脚本 .......................................... 312 
15.2.1 **个 Lua脚本 .............................. 312 
15.2.2 异步处理 ......................................... 313 
15.2.3 Splash对象属性 .............................. 314 
15.2.4 go方法 ........................................... 318 
15.2.5 wait方法 ......................................... 319 
15.2.6 jsfunc方法 ...................................... 320 
15.2.7 evaljs方法 ...................................... 320 
15.2.8 runjs方法 ....................................... 320 
15.2.9 autoload方法 .................................. 321 
15.2.10 call_later方法 ............................... 322 
15.2.11 http_get方法 ................................. 323 
15.2.12 http_post方法 ............................... 324 
15.2.13 set_content方法 ............................ 325 
15.2.14 html方法 ...................................... 325 
15.2.15 png方法 ........................................ 326 
15.2.16 jpeg方法 ....................................... 326 
15.2.17 har方法 ........................................ 326 
15.2.18 其他方法 ....................................... 327 
15.3  使用 CSS选择器 ......................................... 331 
15.3.1 select方法 ...................................... 331 
15.3.2 select_all方法 ................................. 332 
15.4  模拟鼠标和键盘的动作................................ 333 
15.5  Splash HTTP API ........................................ 334 
15.6  项目实战：使用 Splash Lua抓取京东搜索结果 ..................................................... 338 15.7  小结............................................................ 340
第 16章抓取移动 App的数据 ................. 341 
16.1  使用 Charles ............................................... 341 
16.1.1 抓取 HTTP数据包 ........................... 342 
16.1.2 安装 PC端证书 ............................... 344 
16.1.3 在手机端安装证书 ........................... 345 
16.1.4 监听 HTTPS数据包 ......................... 346 
16.2  使用 mitmproxy .......................................... 348 
16.2.1 安装 mitmproxy............................... 348 
16.2.2 在 PC端安装 mitmproxy证书 .......... 349 
16.2.3 在移动端安装 mitmproxy证书......... 352 
16.2.4  mitmproxy有哪些功能 .................... 353 
16.2.5  设置手机的代理 .............................. 353 
16.2.6  用 mitmproxy监听 App的请求与响应数据 ......................................... 354 16.2.7  使用 mitmproxy编辑请求信息......... 356 
16.2.8  mitmdump与 Python对接 ............... 357 
16.2.9  使用 mitmweb监听请求与响应........ 361 
16.3  项目实战：实时抓取“得到” App在线课程 .............................................. 363 16.4  小结............................................................ 367
第 17章使用 Appium在移动端抓取数据 ... 368 17.1  安装 Appium ............................................... 368 
17.1.1  安装 Appium桌面端 ........................ 368 
17.1.2  配置 Android开发环境 .................... 370 
17.1.3  配置 iOS开发环境 .......................... 371 
17.2  Appium的基本使用方法 ............................. 372 
17.2.1  启动 Appium服务 ........................... 372 
17.2.2  查找 Android App的 Package和入口 Activity................................... 374 17.2.3  控制 App ......................................... 376 
17.3  使用 Python控制手机 App .......................... 379 
17.4  AppiumPythonClient API............................. 380 
17.4.1  初始化（Remote类）........................ 380 
17.4.2  查找元素 ......................................... 381 
17.4.3  单击元素 ......................................... 381 
17.4.4  屏幕拖动 ......................................... 382 
17.4.5  屏幕滑动 ......................................... 382 
17.4.6  拖曳操作 ......................................... 383 
17.4.7  文本输入 ......................................... 383 
17.4.8  动作链 ............................................ 383 
17.5  项目实战：利用 Appium抓取微信朋友圈信息 ............................................................ 384 17.6  小结............................................................ 388
第 18章多线程和多进程爬虫 .................. 389 
18.1  线程与进程 ................................................. 389 
18.1.1  进程 ................................................ 389 
18.1.2  线程 ................................................ 390 
18.2  Python与线程 ............................................. 390 
18.2.1  使用单线程执行程序 ....................... 390 
18.2.2  使用多线程执行程序 ....................... 391 
18.2.3  为线程函数传递参数 ....................... 393 
18.2.4  线程和锁 ......................................... 394 
18.3  高级线程模块（threading） ........................... 395 
18.3.1  Thread类与线程函数 ....................... 395 
18.3.2  Thread类与线程对象 ....................... 396 
18.3.3  从 Thread类继承 ............................. 398 
18.4  线程同步..................................................... 399 
18.4.1  线程锁 ............................................ 400 
18.4.2  信号量 ............................................ 402 
18.5  生产者—消费者问题与 queue模块 .............. 405 
18.6  多进程 ........................................................ 407 
18.7  项目实战：抓取豆瓣音乐 Top250排行榜（多线程版） .................................................. 408 18.8  项目实战：抓取豆瓣音乐 Top250排行榜（多进程版） .................................................. 411 18.9  小结............................................................ 412
第 19章网络爬虫框架：Scrapy.............. 413 
19.1  Scrapy基础知识 ......................................... 413 
19.1.1  Scrapy简介 ..................................... 413 
19.1.2  Scrapy安装 ..................................... 414 
19.1.3  Scrapy Shell抓取 Web资源 ............. 415 
19.2  用 Scrapy编写网络爬虫 .............................. 417 
19.2.1  创建和使用 Scrapy工程 .................. 417 
19.2.2  在 PyCharm中使用 Scrapy .............. 419 
19.2.3  在 PyCharm中使用扩展工具运行 Scrapy程序 ..................................... 421 19.2.4  使用 Scrapy抓取数据，并通过 XPath指定解析规则 .................................. 423 19.2.5  将抓取到的数据保存为多种格式的文件 ................................................ 424 19.2.6  使用 ItemLoader保存单条抓取的数据 ................................................ 426 19.2.7  使用 ItemLoader保存多条抓取的数据 ................................................ 428 19.2.8 抓取多个 URL ................................. 430 
19.3 Scrapy的高级应用 ...................................... 431 
19.3.1 处理登录页面 .................................... 431 
19.3.2 处理带隐藏文本框的登录页面 ......... 434 
19.3.3 通过 API抓取天气预报数据 ............ 436 
19.3.4 从 CSV格式转换到 JSON格式 ........ 443 
19.3.5 下载器中间件 .................................. 447 
19.3.6 爬虫中间件 ..................................... 452 
19.3.7 Item管道 ........................................ 455 
19.3.8 通用爬虫 ......................................... 465 
19.4 小结............................................................ 474
第 20章综合爬虫项目：可视化爬虫 ........ 475 
20.1 项目简介..................................................... 475 
20.2 主界面设计和实现 ....................................... 477 
20.3 获取商品页数和每页商品数 ......................... 478 
20.4 并发抓取商品列表 ....................................... 479 
20.5 数据库操作类 .............................................. 481 
20.6 情感分析..................................................... 484 
20.7 抓取和分析商品评论数据 ............................ 485 
20.8 可视化评论数据 .......................................... 486 
20.9 小结............................................................ 488 
