Spark与Hadoop大数据分析 PDF下载 文卡特.安卡姆 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711156941
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711156941
<p>书名:Spark与Hadoop大数据分析</p><p>作者:文卡特.安卡姆</p><p>页数:234</p><p>定价:¥59.0</p><p>出版社:机械工业出版社</p><p>出版日期:2017-07-01</p><p>ISBN:9787111569411</p><p><h2>本书特色</h2></p>[<p>
本书介绍了ApacheSpark和Hadoop的基础知识，并深入探讨了所有Spark组件：SparkCore、SparkSQL、DataFrame、DataSet、普通流、结构化流、MLlib、Graphx，以及Hadoop的核心组件（HDFS、MapReduce和Yarn）等，此外，也讲解了在Spark Hadoop集群中实现的示例。
                                        </p>]<p><h2>目录</h2></p>
    Contents　目　　录译者序前言第1章　从宏观视角看大数据分析11.1　大数据分析以及 Hadoop 和 Spark 在其中承担的角色31.1.1　典型大数据分析项目的生命周期41.1.2　Hadoop和Spark承担的角色61.2　大数据科学以及Hadoop和Spark在其中承担的角色 61.2.1　从数据分析到数据科学的根本性转变 61.2.2　典型数据科学项目的生命周期 81.2.3　Hadoop和Spark 承担的角色91.3　工具和技术91.4　实际环境中的用例111.5　小结12第2章　Apache Hadoop和Apache Spark入门132.1　Apache Hadoop概述132.1.1　Hadoop 分布式文件系统 142.1.2　HDFS 的特性152.1.3　MapReduce 162.1.4　MapReduce 的特性 172.1.5　MapReduce v1与MapReduce v2对比172.1.6　YARN 182.1.7　Hadoop上的存储选择202.2　Apache Spark概述242.2.1　Spark 的发展历史 242.2.2　Apache Spark 是什么252.2.3　Apache Spark 不是什么262.2.4　MapReduce 的问题 272.2.5　Spark 的架构282.3　为何把 Hadoop 和 Spark 结合使用312.3.1　Hadoop 的特性312.3.2　Spark 的特性312.4　安装 Hadoop 和 Spark 集群332.5　小结36第3章　深入剖析Apache Spark373.1　启动 Spark 守护进程 373.1.1　使用CDH 383.1.2　使用 HDP、MapR 和Spark 预制软件包383.2　学习Spark的核心概念 393.2.1　使用 Spark 的方法 393.2.2　弹性分布式数据集 413.2.3　Spark 环境433.2.4　变换和动作443.2.5　RDD 中的并行度463.2.6　延迟评估 493.2.7　谱系图503.2.8　序列化 513.2.9　在 Spark 中利用 Hadoop文件格式 523.2.10　数据的本地性 533.2.11　共享变量 543.2.12　键值对 RDD 553.3　Spark 程序的生命周期 553.3.1　流水线 573.3.2　Spark 执行的摘要 583.4　Spark 应用程序593.4.1　Spark Shell 和 Spark 应用程序593.4.2　创建 Spark 环境593.4.3　SparkConf 593.4.4　SparkSubmit 603.4.5　Spark 配置项的优先顺序613.4.6　重要的应用程序配置 613.5　持久化与缓存 623.5.1　存储级别 623.5.2　应该选择哪个存储级别633.6　Spark 资源管理器：Standalone、YARN和Mesos633.6.1　本地和集群模式633.6.2　集群资源管理器 643.7　小结 67第4章　利用Spark SQL、Data-Frame和Dataset进行大数据分析694.1　Spark SQL 的发展史 704.2　Spark SQL 的架构714.3　介绍Spark SQL的四个组件724.4　DataFrame 和 Dataset 的演变744.4.1　RDD 有什么问题744.4.2　RDD 变换与 Dataset 和DataFrame 变换754.5　为什么要使用 Dataset 和DataFrame754.5.1　优化 764.5.2　速度 764.5.3　自动模式发现 774.5.4　多数据源，多种编程语言774.5.5　RDD 和其他 API 之间的互操作性774.5.6　仅选择和读取必要的数据784.6　何时使用 RDD、Dataset 和DataFrame784.7　利用 DataFrame 进行分析  784.7.1　创建 SparkSession 794.7.2　创建 DataFrame 794.7.3　把DataFrame转换为RDD824.7.4　常用的 Dataset/DataFrame操作 834.7.5　缓存数据844.7.6　性能优化 844.8　利用 Dataset API 进行分析854.8.1　创建 Dataset 854.8.2　把 DataFrame 转换为Dataset 864.8.3　利用数据字典访问元数据874.9　Data Sources API 874.9.1　读和写函数 884.9.2　内置数据源 884.9.3　外部数据源 934.10　把 Spark SQL 作为分布式 SQL引擎 974.10.1　把 Spark SQL 的 Thrift 服务器用于 JDBC / ODBC访问974.10.2　使用 beeline 客户端查询数据 984.10.3　使用 spark-sql CLI 从 Hive查询数据994.10.4　与 BI 工具集成1004.11　Hive on Spark 1004.12　小结100第5章　利用Spark Streaming和Structured Streaming进行实时分析1025.1　实时处理概述 1035.1.1　Spark Streaming 的优缺点 1045.1.2　Spark Streaming 的发展史1045.2　Spark Streaming 的架构 1045.2.1　Spark Streaming 应用程序流1065.2.2　无状态和有状态的流处理1075.3　Spark Streaming 的变换和动作 1095.3.1　union 1095.3.2　join 1095.3.3　transform 操作 1095.3.4　updateStateByKey 1095.3.5　mapWithState 1105.3.6　窗口操作 1105.3.7　输出操作 1115.4　输入数据源和输出存储 1115.4.1　基本数据源 1125.4.2　高级数据源 1125.4.3　自定义数据源1125.4.4　接收器的可靠性 1125.4.5　输出存储1135.5　使用 Kafka 和 HBase 的 Spark Streaming1135.5.1　基于接收器的方法 1145.5.2　直接方法（无接收器）1165.5.3　与 HBase 集成1175.6　Spark Streaming 的高级概念1185.6.1　使用 DataFrame1185.6.2　MLlib 操作1195.6.3　缓存/持久化 1195.6.4　Spark Streaming 中的容错机制 1195.6.5　Spark Streaming 应用程序的性能调优 1215.7　监控应用程序 1225.8　结构化流概述1235.8.1　结构化流应用程序的工作流1235.8.2　流式 Dataset 和流式
