CUDA C编程权威指南 PDF下载 程润伟 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711156547
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711156547
<p>书名:CUDA C编程权威指南</p><p>作者:程润伟</p><p>页数:412</p><p>定价:¥99.0</p><p>出版社:机械工业出版社</p><p>出版日期:2017-06-01</p><p>ISBN:9787111565475</p><p><h2>本书特色</h2></p>[<p>
本书主要介绍了如何使用GPU和利用CUDAC语言对其进行编程的。首先从基本的CUDA概念及结构讲起，一步一步地引导读者进入CUDA的内部世界，由浅入深地介绍了其编程要求及其内部架构，使读者对其有了整体印象后，逐步深入了解其内部机能，后介绍了GPU的一些专用函数和注意事项。
                                        </p>]<p><h2>目录</h2></p>
    目　　录 译者序推荐序自序作者简介技术审校者简介前言致谢第1章　基于CUDA的异构并行计算11.1　并行计算11.1.1　串行编程和并行编程21.1.2　并行性31.1.3　计算机架构41.2　异构计算61.2.1　异构架构71.2.2　异构计算范例91.2.3　CUDA：一种异构计算平台101.3　用GPU输出Hello World121.4　使用CUDA C编程难吗151.5　总结161.6　习题16第2章　CUDA编程模型182.1　CUDA编程模型概述182.1.1　CUDA编程结构192.1.2　内存管理202.1.3　线程管理242.1.4　启动一个CUDA核函数292.1.5　编写核函数302.1.6　验证核函数312.1.7　处理错误322.1.8　编译和执行322.2　给核函数计时352.2.1　用CPU计时器计时352.2.2　用nvprof工具计时392.3　组织并行线程402.3.1　使用块和线程建立矩阵索引402.3.2　使用二维网格和二维块对矩阵求和442.3.3　使用一维网格和一维块对矩阵求和472.3.4　使用二维网格和一维块对矩阵求和482.4　设备管理502.4.1　使用运行时API查询GPU信息502.4.2　确定*优GPU532.4.3　使用nvidia-smi查询GPU信息532.4.4　在运行时设置设备542.5　总结542.6　习题55第3章　CUDA执行模型563.1　CUDA执行模型概述563.1.1　GPU架构概述573.1.2　Fermi架构593.1.3　Kepler架构613.1.4　配置文件驱动优化653.2　理解线程束执行的本质673.2.1　线程束和线程块673.2.2　线程束分化693.2.3　资源分配743.2.4　延迟隐藏763.2.5　占用率783.2.6　同步813.2.7　可扩展性823.3　并行性的表现833.3.1　用nvprof检测活跃的线程束843.3.2　用nvprof检测内存操作853.3.3　增大并行性863.4　避免分支分化883.4.1　并行归约问题883.4.2　并行归约中的分化893.4.3　改善并行归约的分化933.4.4　交错配对的归约953.5　展开循环973.5.1　展开的归约973.5.2　展开线程的归约993.5.3　完全展开的归约1013.5.4　模板函数的归约1023.6　动态并行1043.6.1　嵌套执行1053.6.2　在GPU上嵌套Hello World1063.6.3　嵌套归约1093.7　总结1133.8　习题113第4章　全局内存1154.1　CUDA内存模型概述1154.1.1　内存层次结构的优点1164.1.2　CUDA内存模型1174.2　内存管理1244.2.1　内存分配和释放1244.2.2　内存传输1254.2.3　固定内存1274.2.4　零拷贝内存1284.2.5　统一虚拟寻址1334.2.6　统一内存寻址1344.3　内存访问模式1354.3.1　对齐与合并访问1354.3.2　全局内存读取1374.3.3　全局内存写入1454.3.4　结构体数组与数组结构体1474.3.5　性能调整1514.4　核函数可达到的带宽1544.4.1　内存带宽1544.4.2　矩阵转置问题1554.5　使用统一内存的矩阵加法1674.6　总结1714.7　习题172第5章　共享内存和常量内存1745.1　CUDA共享内存概述1745.1.1　共享内存1755.1.2　共享内存分配1765.1.3　共享内存存储体和访问模式1765.1.4　配置共享内存量1815.1.5　同步1835.2　共享内存的数据布局1855.2.1　方形共享内存1855.2.2　矩形共享内存1935.3　减少全局内存访问1995.3.1　使用共享内存的并行归约1995.3.2　使用展开的并行归约2025.3.3　使用动态共享内存的并行归约2045.3.4　有效带宽2055.4　合并的全局内存访问2055.4.1　基准转置内核2055.4.2　使用共享内存的矩阵转置2075.4.3　使用填充共享内存的矩阵转置2105.4.4　使用展开的矩阵转置2115.4.5　增大并行性2145.5　常量内存2155.5.1　使用常量内存实现一维模板2155.5.2　与只读缓存的比较2175.6　线程束洗牌指令2195.6.1　线程束洗牌指令的不同形式2205.6.2　线程束内的共享数据2225.6.3　使用线程束洗牌指令的并行归约2265.7　总结2275.8　习题228第6章　流和并发2306.1　流和事件概述2316.1.1　CUDA流2316.1.2　流调度2346.1.3　流的优先级2356.1.4　CUDA事件2356.1.5　流同步2376.2　并发内核执行2406.2.1　非空流中的并发内核2406.2.2　Fermi GPU上的虚假依赖关系2426.2.3　使用OpenMP的调度操作2446.2.4　用环境变量调整流行为2456.2.5　GPU资源的并发限制2466.2.6　默认流的阻塞行为2476.2.7　创建流间依赖关系2486.3　重叠内核执行和数据传输2496.3.1　使用深度优先调度重叠2496.3.2　使用广度优先调度重叠2526.4　重叠GPU和CPU执行2546.5　流回调2556.6　总结2566.7　习题257第7章　调整指令级原语2587.1　CUDA指令概述2597.1.1　浮点指令2597.1.2　内部函数和标准函数2617.1.3　原子操作指令2627.2　程序优化指令2647.2.1　单精度与双精度的比较2647.2.2　标准函数与内部函数的比较2667.2.3　了解原子指令2727.2.4　综合范例2777.3　总结2797.4　习题280第8章　GPU加速库和OpenACC2818.1　CUDA库概述2828.1.1　CUDA库支持的作用域2838.1.2　通用的CUDA库工作流2838.2　cuSPARSE库2858.2.1　cuSPARSE数据存储格
