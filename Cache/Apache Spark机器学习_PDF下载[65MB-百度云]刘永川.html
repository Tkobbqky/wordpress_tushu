Apache Spark机器学习 PDF下载 刘永川 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711156255
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711156255
<p>书名:Apache Spark机器学习</p><p>作者:刘永川</p><p>页数:208</p><p>定价:¥59.0</p><p>出版社:机械工业出版社</p><p>出版日期:2017-03-01</p><p>ISBN:9787111562559</p><p><h2>本书特色</h2></p>[<p>
本书包装了一系列项目“蓝图”，展示了Spark可以帮你解决的一些有趣挑战，读者在将理论知识实践于一些实际项目之前，会了解到如何使用Sparknotebook，以及如何访问、清洗和连接不同的数据集，你将在其中了解Spark机器学习如何帮助你完成从欺诈检测到分析客户流失等各种工作。你还将了解如何使用Spark的并行计算能力构建推荐引擎。
                                        </p>]<p><h2>目录</h2></p>
    目　　录?Contents译者序前　言第1章　Spark机器学习简介  11.1　Spark概述和技术优势  21.1.1　Spark概述  21.1.2　Spark优势  31.2　在机器学习中应用Spark计算  41.3　机器学习算法  51.4　MLlib  61.5　Spark RDD和DataFrame  81.5.1　Spark RDD  81.5.2　Spark DataFrame  91.5.3　R语言DataFrame API  101.5.4　机器学习框架、RM4E和Spark计算  111.5.5　机器学习框架  121.5.6　RM4E  131.5.7　Spark计算框架  131.6　机器学习工作流和Spark pipeline  141.7　机器学习工作流示例  161.8　Spark notebook简介  191.8.1　面向机器学习的notebook方法  191.8.2　Spark notebook  211.9　小结  22第2章　Spark机器学习的数据准备  242.1　访问和加载数据集  252.1.1　访问公开可用的数据集  252.1.2　加载数据集到Spark  262.1.3　数据集探索和可视化  272.2　数据清洗  292.2.1　处理数据不完备性  302.2.2　在Spark中进行数据清洗  312.2.3　更简便的数据清洗  322.3　一致性匹配  332.3.1　一致性问题  332.3.2　基于Spark的一致性匹配  342.3.3　实体解析  342.3.4　更好的一致性匹配  352.4　数据集重组  362.4.1　数据集重组任务  362.4.2　使用Spark SQL进行数据集重组  372.4.3　在Spark上使用R语言进行数据集重组  382.5　数据集连接  392.5.1　数据连接及其工具——Spark SQL  392.5.2　Spark中的数据集连接  402.5.3　使用R语言数据表程序包进行数据连接  402.6　特征提取  422.6.1　特征开发的挑战  422.6.2　基于Spark MLlib的特征开发  432.6.3　基于R语言的特征开发  452.7　复用性和自动化  452.7.1　数据集预处理工作流  462.7.2　基于Spark pipeline的数据集预处理  472.7.3　数据集预处理自动化  472.8　小结  49第3章　基于Spark的整体视图  513.1　Spark整体视图  513.1.1　例子  523.1.2　简洁快速的计算  543.2　整体视图的方法  553.2.1　回归模型  563.2.2　SEM方法  573.2.3　决策树  573.3　特征准备  583.3.1　PCA  593.3.2　使用专业知识进行分类分组  593.3.3　特征选择  603.4　模型估计  613.4.1　MLlib实现  623.4.2　R notebook实现  623.5　模型评估  633.5.1　快速评价  633.5.2　RMSE  643.5.3　ROC曲线  653.6　结果解释  663.7　部署  663.7.1　仪表盘  673.7.2　规则  683.8　小结  68第4章　基于Spark的欺诈检测  694.1　Spark欺诈检测  704.1.1　例子  704.1.2　分布式计算  714.2　欺诈检测方法  724.2.1　随机森林  734.2.2　决策树  744.3　特征提取  744.3.1　从日志文件提取特征  754.3.2　数据合并  754.4　模型估计  764.4.1　MLlib实现  774.4.2　R notebook实现  774.5　模型评价  774.5.1　快速评价  784.5.2　混淆矩阵和误报率  784.6　结果解释  794.7　部署欺诈检测  804.7.1　规则  814.7.2　评分  814.8　小结  82第5章　基于Spark的风险评分  835.1　Spark用于风险评分  845.1.1　例子  845.1.2　Apache Spark notebook  855.2　风险评分方法  875.2.1　逻辑回归  875.2.2　随机森林和决策树  885.3　数据和特征准备  895.4　模型估计  915.4.1　在Data Scientist Workbench上应用R notebook  915.4.2　实现R notebook  925.5　模型评价  935.5.1　混淆矩阵  935.5.2　ROC分析  935.5.3　Kolmogorov-Smirnov检验  945.6　结果解释  955.7　部署  965.8　小结  97第6章　基于Spark的流失预测  996.1　Spark流失预测  996.1.1　例子  1006.1.2　Spark计算  1006.2　流失预测的方法  1016.2.1　回归模型  1026.2.2　决策树和随机森林  1036.3　特征准备  1046.3.1　特征提取  1046.3.2　特征选择  1056.4　模型估计  1056.5　模型评估  1076.6　结果解释  1096.7　部署  1106.7.1　评分  1116.7.2　干预措施推荐  1116.8　小结  111第7章　基于Spark的产品推荐  1127.1　基于Apache Spark 的产品推荐引擎  1127.1.1　例子  1137.1.2　基于Spark平台的SPSS  1147.2　产品推荐方法  1177.2.1　协同过滤  1177.2.2　编程准备  1187.3　基于SPSS的数据治理  1197.4　模型估计  1207.5　模型评价  1217.6　产品推荐部署  1227.7　小结  125第8章　基于Spark的学习分析  1268.1　Spark流失预测  1278.1.1　例子  1278.1.2　Spark计算  1288.2　流失预测方法  1308.2.1　回归模型  1308.2.2　决策树  1318.3　特征准备  1318.3.1　特征开发  1338.3.2　特征选择  1338.4　模型估计  1358.5　模型评价  1378.5.1　快速评价  1388.5.2　混淆矩阵和错误率  1388.6　结果解释  1398.6.1　计算干预影响  1408.6.2　计算主因子影响  1408.7　部署  1418.7.1　规则  1418.7.2　评分  1428.8　小结
