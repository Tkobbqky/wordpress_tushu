Python与机器学习实战 PDF下载 何宇健 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#712131720
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#712131720
<p>书名:Python与机器学习实战</p><p>作者:何宇健</p><p>页数:328</p><p>定价:¥69.0</p><p>出版社:电子工业出版社</p><p>出版日期:2017-07-01</p><p>ISBN:9787121317200</p><p><h2>本书特色</h2></p>[<p>
Python与机器学习这一话题是如此的宽广，仅靠一本书自然不可能涵盖到方方面面，甚至即使出一个系列也难能做到这点。单就机器学习而言，其领域就包括但不限于如下：有监督学习（Supervised Learning），无监督学习（Unsupervised Learning）和半监督学习（Semi-Supervised Learning）。而具体的问题又大致可以分两类：分类问题（Classification）和回归问题（Regression）。Python本身带有许多机器学习的第三方库，但本书在绝大多数情况下只会用到Numpy这个基础的科学计算库来进行算法代码的实现。这样做的目的是希望读者能够从实现的过程中更好地理解机器学习算法的细节，以及了解Numpy的各种应用。不过作为补充，本书会在适当的时候应用scikit-learn这个成熟的第三方库中的模型。本书适用于想了解传统机器学习算法的学生和从业者，想知道如何高效实现机器的算法的程序员，以及想了解机器学习的算法能如何进行应用的职员、经理等。
                                        </p>]<p><h2>内容简介</h2></p>[<p>算法与代码兼顾，理论与实践结合
很丰富：7种算法，50段实现，55个实例，总代码量5295行，全面而不冗余
很扎实：对经典有效的机器学习算法的核心内容进行了相当详细的推导
很应用：将理论实打实地用Python代码写出来，可以解决一定的任务
很前沿：叙述了TensorFlow框架、Inception-v3 from Google、迁移学习等前沿技术 </p>]<p><h2>作者简介</h2></p>[<p>毕业于北京大学数学系，就职于北京霄飞亚科技有限公司，有10多年C语言开发经验，后来转做Python，对机器学习、神经网络、贝叶斯算法有深入研究。曾经参与过实时目标跟踪算法研究；行人检测及其python的实现；基于神经网络的目标检测算法研究。</p>]<p><h2>目录</h2></p>
    目录第1章　Python与机器学习入门	11.1  机器学习绪论	11.1.1  什么是机器学习	21.1.2  机器学习常用术语	31.1.3  机器学习的重要性	61.2  人生苦短，我用Python	71.2.1  为何选择Python	71.2.2  Python 在机器学习领域的优势	81.2.3  Anaconda的安装与使用	81.3  **个机器学习样例	121.3.1  获取与处理数据	131.3.2  选择与训练模型	141.3.3  评估与可视化结果	151.4  本章小结	17第2章　贝叶斯分类器	182.1  贝叶斯学派	182.1.1  贝叶斯学派与频率学派	192.1.2  贝叶斯决策论	192.2  参数估计	202.2.1  极大似然估计（ML估计）	212.2.2  极大后验概率估计（MAP估计）	222.3  朴素贝叶斯	232.3.1  算法陈述与基本架构的搭建	232.3.2  MultinomialNB的实现与评估	312.3.3  GaussianNB的实现与评估	402.3.4  MergedNB的实现与评估	432.3.5  算法的向量化	502.4  半朴素贝叶斯与贝叶斯网	532.4.1  半朴素贝叶斯	532.4.2  贝叶斯网	542.5  相关数学理论	552.5.1  贝叶斯公式与后验概率	552.5.2  离散型朴素贝叶斯算法	562.5.3  朴素贝叶斯和贝叶斯决策	582.6  本章小结	59第3章　决策树	603.1  数据的信息	603.1.1  信息论简介	613.1.2  不确定性	613.1.3  信息的增益	653.1.4  决策树的生成	683.1.5  相关的实现	773.2  过拟合与剪枝	923.2.1  ID3、C4.5的剪枝算法	933.2.2  CART剪枝	1003.3  评估与可视化	1033.4  相关数学理论	1113.5  本章小结	113第4章　集成学习	1144.1  “集成”的思想	1144.1.1  众擎易举	1154.1.2  Bagging与随机森林	1154.1.3  PAC框架与Boosting	1194.2  随机森林算法	1204.3  AdaBoost算法	1244.3.1  AdaBoost算法陈述	1244.3.2  弱模型的选择	1264.3.3  AdaBoost的实现	1274.4  集成模型的性能分析	1294.4.1  随机数据集上的表现	1304.4.2  异或数据集上的表现	1314.4.3  螺旋数据集上的表现	1344.4.4  蘑菇数据集上的表现	1364.5  AdaBoost算法的解释	1384.6  相关数学理论	1394.6.1  经验分布函数	1394.6.2  AdaBoost与前向分步加法模型	1404.7  本章小结	142第5章　支持向量机	1445.1  感知机模型	1455.1.1  线性可分性与感知机策略	1455.1.2  感知机算法	1485.1.3  感知机算法的对偶形式	1515.2  从感知机到支持向量机	1535.2.1  间隔*大化与线性SVM	1545.2.2  SVM算法的对偶形式	1585.2.3  SVM的训练	1615.3  从线性到非线性	1635.3.1  核技巧简述	1635.3.2  核技巧的应用	1665.4  多分类与支持向量回归	1805.4.1  一对多方法（One-vs-Rest）	1805.4.2  一对一方法（One-vs-One）	1815.4.3  有向无环图方法（Directed Acyclic Graph Method）	1815.4.4  支持向量回归（Support Vector Regression）	1825.5  相关数学理论	1835.5.1  梯度下降法	1835.5.2  拉格朗日对偶性	1855.6  本章小结	187第6章　神经网络	1886.1  从感知机到多层感知机	1896.2  前向传导算法	1926.2.1  算法概述	1936.2.2  激活函数（Activation Function）	1956.2.3  损失函数（Cost Function）	1996.3  反向传播算法	2006.3.1  算法概述	2006.3.2  损失函数的选择	2026.3.3  相关实现	2056.4  特殊的层结构	2116.5  参数的更新	2146.5.1  Vanilla Update	2176.5.2  Momentum Update	2176.5.3  Nesterov Momentum Update	2196.5.4  RMSProp	2206.5.5  Adam	2216.5.6  Factory	2226.6  朴素的网络结构	2236.7  “大数据”下的网络结构	2276.7.1  分批（Batch）的思想	2286.7.2  交叉验证	2306.7.3  进度条	2316.7.4  计时器	2336.8  相关数学理论	2356.8.1  BP算法的推导	2356.8.2  Softmax   log-likelihood组合	2386.9  本章小结	240第7章　卷积神经网络	2417.1  从NN到CNN	2427.1.1  “视野”的共享	2427.1.2  前向传导算法	2437.1.3  全连接层（Fully Connected Layer）	2507.1.4  池化（Pooling）	2517.2  利用TensorFlow重写NN	2527.2.1  反向传播算法	2527.2.2  重写Layer结构	2537.2.3  实现SubLayer结构	2557.2.4  重写CostLayer结构	2617.2.5  重写网络结构	2627.3  将NN扩展为CNN	2637.3.1  实现卷积层	2637.3.2  实现池化层	2667.3.3  实现CNN中的特殊层结构	2677.3.4  实现LayerFactory	2687.3.5  扩展网络结构	2707.4  CNN的性能	2727.4.1  问题描述	2727.4.2  搭建CNN模型	2737.4.3  模型分析	2807.4.4  应用CNN的方法	2837.4.5  Inception	2867.5  本章小结	289附录A　Python入门	290附录B　Numpy入门	303附录C　TensorFlow入门	310
