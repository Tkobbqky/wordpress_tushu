Python机器学习算法 PDF下载 赵志勇 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#712131319
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#712131319
<p>书名:Python机器学习算法</p><p>作者:赵志勇</p><p>页数:343</p><p>定价:¥69.0</p><p>出版社:电子工业出版社</p><p>出版日期:2017-07-01</p><p>ISBN:9787121313196</p><p><h2>相关资料</h2></p>[<p>在人工智能时代，机器学习已经成了互联网从业人员和在校学生的一门必修课。市场上不乏机器学习相关的书籍，但大都晦涩难懂而缺乏应用场景。本书是作者在新浪微博广告业务上一手的实践经验和心得体会，具有极佳的实用性，非常适合于对机器学习感兴趣但没有经验的开发人员，和渴望了解“理论知识如何在业务中应用”的在校学生，相信你们一定可以从中找到想要的答案。
——新浪微博高级技术经理
姜贵彬
 
本书没有使用高深复杂的数学逻辑来解释机器学习，而是从直观简洁的介绍入手，通俗易懂，再辅助于代码实现帮助读者理解算法细节，是机器学习入门一本不可多得的好书，推荐。
——百度资深技术专家
毛钦
 
本书从具体的代码开始去理解抽象的算法，给读者一种脚踏实地的感觉，推荐给所有工程出身有志于算法的工程师。
——阿里妈妈算法工程技术专家
易慧民
 
本书对常用的机器学习算法进行了深入和全面的介绍，书中大量的代码清单令人印象尤为深刻，确实是一本实用易懂、快速入门的好书。
——美团·大众点评资深技术专家
潘文彬</p>]<p><h2>本书特色</h2></p>[<p>
本书是一本机器学习入门读物，注重理论与实践的结合。全书主要包括6个部分，每个部分均以典型的机器学习算法为例，从算法原理出发，由浅入深，详细分析算法的理论，并配合目前流行的Python语言，从零开始，实现每一个算法，以加强对机器学习算法理论的理解、增强实际的算法实践能力，*终达到熟练掌握每一个算法的目的。与其他机器学习类书相比，本书同时包含算法理论的介绍和算法的实践，以理论支撑实践，同时，又将复杂、枯燥的理论用简单易懂的形式表达出来，促进对理论的理解。
                                        </p>]<p><h2>作者简介</h2></p>[<p>赵志勇，毕业于武汉大学计算机学院，CSDN博主，博客地址http://blog.csdn.net/google19890102，现就职于新浪微博，从事计算广告的算法工作。对机器学习、优化算法具有浓厚的兴趣。</p>]<p><h2>目录</h2></p>
    0  绪论	10.1  机器学习基础	10.1.1  机器学习的概念	10.1.2  机器学习算法的分类	20.2  监督学习	30.2.1  监督学习	30.2.2  监督学习的流程	30.2.3  监督学习算法	40.3  无监督学习	40.3.1  无监督学习	40.3.2  无监督学习的流程	40.3.3  无监督学习算法	50.4  推荐系统和深度学习	60.4.1  推荐系统	60.4.2  深度学习	60.5  Python和机器学习算法实践	6参考文献	7**部分  分类算法1  Logistic Regression	101.1  Logistic Regression模型	101.1.1  线性可分VS线性不可分	101.1.2  Logistic Regression模型	111.1.3  损失函数	131.2  梯度下降法	141.2.1  梯度下降法的流程	141.2.2  凸优化与非凸优化	151.2.3  利用梯度下降法训练Logistic Regression模型	171.3  梯度下降法的若干问题	181.3.1  选择下降的方向	181.3.2  步长的选择	191.4  Logistic Regression算法实践	201.4.1  利用训练样本训练Logistic Regression模型	201.4.2  *终的训练效果	221.4.3  对新数据进行预测	23参考文献	262  Softmax Regression	272.1  多分类问题	272.2  Softmax Regression算法模型	282.2.1  Softmax Regression模型	282.2.2  Softmax Regression算法的代价函数	282.3  Softmax Regression算法的求解	292.4  Softmax Regression与Logistic Regression的关系	312.4.1  Softmax Regression中的参数特点	312.4.2  由Softmax Regression到Logistic Regression	312.5  Softmax Regression算法实践	322.5.1  对Softmax Regression算法的模型进行训练	332.5.2  *终的模型	342.5.3  对新的数据的预测	35参考文献	393  Factorization Machine	403.1  Logistic Regression算法的不足	403.2  因子分解机FM的模型	423.2.1  因子分解机FM模型	423.2.2  因子分解机FM可以处理的问题	433.2.3  二分类因子分解机FM算法的损失函数	433.3  FM算法中交叉项的处理	433.3.1  交叉项系数	433.3.2  模型的求解	443.4  FM算法的求解	453.4.1  随机梯度下降（Stochastic Gradient Descent）	453.4.2  基于随机梯度的方式求解	453.4.3  FM算法流程	463.5  因子分解机FM算法实践	493.5.1  训练FM模型	503.5.2  *终的训练效果	533.5.3  对新的数据进行预测	55参考文献	574  支持向量机	584.1  二分类问题	584.1.1  二分类的分隔超平面	584.1.2  感知机算法	594.1.3  感知机算法存在的问题	614.2  函数间隔和几何间隔	614.2.1  函数间隔	624.2.2  几何间隔	624.3  支持向量机	634.3.1  间隔*大化	634.3.2  支持向量和间隔边界	644.3.3  线性支持向量机	654.4  支持向量机的训练	664.4.1  学习的对偶算法	664.4.2  由线性支持向量机到非线性支持向量机	684.4.3  序列*小*优化算法SMO	694.5  支持向量机SVM算法实践	744.5.1  训练SVM模型	744.5.2  利用训练样本训练SVM模型	814.5.3  利用训练好的SVM模型对新数据进行预测	85参考文献	885  随机森林	895.1  决策树分类器	895.1.1  决策树的基本概念	895.1.2  选择*佳划分的标准	915.1.3  停止划分的标准	945.2  CART分类树算法	955.2.1  CART分类树算法的基本原理	955.2.2  CART分类树的构建	955.2.3  利用构建好的分类树进行预测	985.3  集成学习（Ensemble Learning）	995.3.1  集成学习的思想	995.3.2  集成学习中的典型方法	995.4  随机森林（Random Forests）	1015.4.1  随机森林算法模型	1015.4.2  随机森林算法流程	1025.5  随机森林RF算法实践	1045.5.1  训练随机森林模型	1055.5.2  *终的训练结果	1095.5.3  对新数据的预测	110参考文献	1136  BP神经网络	1146.1  神经元概述	1146.1.1  神经元的基本结构	1146.1.2  激活函数	1156.2  神经网络模型	1166.2.1  神经网络的结构	1166.2.2  神经网络中的参数说明	1176.2.3  神经网络的计算	1176.3  神经网络中参数的求解	1186.3.1  神经网络损失函数	1186.3.2  损失函数的求解	1196.3.3  BP神经网络的学习过程	1206.4  BP神经网络中参数的设置	1266.4.1  非线性变换	1266.4.2  权重向量的初始化	1266.4.3  学习率	1276.4.4  隐含层节点的个数	1276.5  BP神经网络算法实践	1276.5.1  训练BP神经网络模型	1286.5.2  *终的训练效果	1326.5.3  对新数据的预测	133参考文献	136第二部分  回归算法7  线性回归	1387.1  基本线性回归	1387.1.1  线性回归的模型	1387.1.2  线性回归模型的损失函数	1397.2  线性回归的*小二乘解法	1407.2.1  线性回归的*小二乘解法	1407.2.2  广义逆的概念	1417.3  牛顿法	1417.3.1  基本牛顿法的原理	1417.3.2  基本牛顿法的流程	1427.3.3  全局牛顿法	1427.3.4  Armijo搜索	1447.3.5  利用全局牛顿法求解线性回归模型	1457.4  利用线性回归进行预测	1467.4.1  训练线性回归模型	1477.4.2  *终的训练结果	1497.4.3  对新数据的预测	1507.5  局部加权线性回归	1527.5.1 局部加权线性回归模型	1527.5.2  局部加权线性回归的*终结果	153参考文献	1548  岭回归和Lasso回归	1558.1  线性回归存在的问题	1558.2  岭回归模型	1568.2.1  岭回归模型	1568.2.2  岭回归模型的求解	1568.3  Lasso回归模型	1578.4  拟牛顿法	1588.4.1  拟牛顿法	1588.4.2  BFGS校正公式的推导	1588.4.3  BFGS校正的算法流程	1598.5  L-BFGS求解岭回归模型	1628.5.1  BGFS算法存在的问题	1628.5.2  L-BFGS算法思路	1628.6  岭回归对数据的预测	1658.6.1  训练岭回归模型	1668.6.2  *终的训练结果	1688.6.3  利用岭回归模型预测新的数据	168参考文献	1719  CART树回归	1729.1  复杂的回归问题	1729.1.1  线性回归模型	1729.1.2  局部加权线性回归	1739.1.3  CART算法	1749.2  CART回归树生成	1759.2.1  CART回归树的划分	1759.2.2  CART回归树的构建	1779.3  CART回归树剪枝	1799.3.1  前剪枝	1799.3.2  后剪枝	1809.4  CART回归树对数据预测	1809.4.1  利用训练数据训练CART回归树模型	1809.4.2  *终的训练结果	1829.4.3  利用训练好的CART回归树模型对新的数据预测	185参考文献	187第三部分  聚类算法10  K-Means	19010.1  相似性的度量	19010.1.1  闵可夫斯基距离	19110.1.2  曼哈顿距离	19110.1.3  欧氏距离	19110.2  K-Means算法原理	19210.2.1  K-Means算法的基本原理	19210.2.2  K-Means算法步骤	19310.2.3  K-Means算法与矩阵分解	19310.3  K-Means算法实践	19510.3.1  导入数据	19610.3.2  初始化聚类中心	19710.3.3  聚类过程	19810.3.4  *终的聚类结果	19910.4  K-Means  算法	20010.4.1  K-Means算法存在的问题	20010.4.2  K-Means  算法的基本思路	20210.4.3  K-Means  算法的过程和*终效果	204参考文献	20511  Mean Shift	20611.1  Mean Shift向量	20611.2  核函数	20711.3  Mean Shift算法原理	20911.3.1  引入核函数的Mean Shift向量	20911.3.2  Mean Shift算法的基本原理	21011.4  Mean Shift算法的解释	21211.4.1  概率密度梯度	21211.4.2  Mean Shift向量的修正	21311.4.3  Mean Shift算法流程	21311.5  Mean Shift算法实践	21711.5.1  Mean Shift的主过程	21811.5.2  Mean Shift的*终聚类结果	219参考文献	22112  DBSCAN	22212.1  基于密度的聚类	22212.1.1  基于距离的聚类算法存在的问题	22212.1.2  基于密度的聚类算法	22512.2  DBSCAN算法原理	22512.2.1  DBSCAN算法的基本概念	22512.2.2  DBSCAN算法原理	22712.2.3  DBSCAN算法流程	22812.3  DBSCAN算法实践	23112.3.1  DBSCAN算法的主要过程	23212.3.2  Mean Shift的*终聚类结果	234参考文献	23613  Label Propagation	23713.1  社区划分	23713.1.1  社区以及社区划分	23713.1.2  社区划分的算法	23813.1.3  社区划分的评价标准	23913.2  Label Propagation算法原理	23913.2.1  Label Propagation算法的基本原理	23913.2.2  标签传播	24013.2.3  迭代的终止条件	24213.3  Label Propagation算法过程	24413.4  Label Propagation算法实践	24413.4.1  导入数据	24513.4.2  社区的划分	24613.4.3  *终的结果	247参考文献	248第四部分  推荐算法14  协同过滤算法	25014.1  推荐系统的概述	25014.1.1  推荐系统	25014.1.2  推荐问题的描述	25114.1.3  推荐的常用方法	25114.2  基于协同过滤的推荐	25214.2.1  协同过滤算法概述	25214.2.2  协同过滤算法的分类	25214.3  相似度的度量方法	25314.3.1  欧氏距离	25414.3.2  皮尔逊相关系数（Pearson Correlation）	25414.3.3  余弦相似度	25414.4  基于协同过滤的推荐算法	25614.4.1  基于用户的协同过滤算法	25614.4.2  基于项的协同过滤算法	25814.5  利用协同过滤算法进行推荐	26014.5.1  导入用户-商品数据	26014.5.2  利用基于用户的协同过滤算法进行推荐	261
